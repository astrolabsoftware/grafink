#!/bin/bash
# Copyright 2020 AstroLab Software
# Author: Yash Datta
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
set -e

if [ $# -le 3 ]; then
  echo "Usage: --config <config-file> --startdate <date> --duration <number of days>"
  exit 1
fi

VARS=""
SPARKVARS=""

# Parse config and rules file paths
while test $# -gt 0
do
  case "$1" in
    --config)
      shift
      CONF_FILE_PATH=$1
      VARS="$VARS--config $1 ";;
    --startdate)
      shift
      VARS="$VARS--startdate $1 ";;
    --duration)
      shift
      VARS="$VARS--duration $1 ";;
    --delete)
      VARS="$VARS--delete ";;
    --driver-memory)
      shift
      SPARKVARS="$SPARKVARS--driver-memory $1 ";;
    --driver-cores)
      shift
      SPARKVARS="$SPARKVARS--driver-cores $1 ";;
    --num-executors)
      shift
      SPARKVARS="$SPARKVARS--num-executors $1 ";;
    --executor-memory)
      shift
      SPARKVARS="$SPARKVARS--executor-memory $1 ";;
    --executor-cores)
      shift
      SPARKVARS="$SPARKVARS--executor-cores $1 ";;
    --total-executor-cores)
      shift
      SPARKVARS="$SPARKVARS--total-executor-cores $1 ";;
    --conf)
      shift
      SPARKVARS="$SPARKVARS--conf $1 ";;
  esac
  shift
done

# Convert file paths to their basenames, since spark just needs base names to refer to these files
CONF_FILE=$(basename $CONF_FILE_PATH)

lib_dir=$(cd "$(dirname ${BASH_SOURCE[0]})"/../lib; pwd)

${{template_declares}}

KRB5_CONF=""

LOG_FILE=$lib_dir/run.out

echo "Running spark-submit..."

DEPLOY_MODE="client"
if [ -z ${SPARK_MASTER} ]; then
  echo "Running spark locally since SPARK_MASTER not defined"
  SPARK_MASTER="local[*]"
  DEPLOY_MODE="client"
  CONF_FILE=$CONF_FILE_PATH
fi

if [ "$DEPLOY_MODE" = "cluster" ]; then
  VARS=${VARS/$CONF_FILE_PATH/$CONF_FILE}
fi

spark-submit \
--master ${SPARK_MASTER} \
--deploy-mode ${DEPLOY_MODE} \
--files $CONF_FILE_PATH \
$SPARKVARS \
--conf spark.rdd.compress=true \
--conf spark.executor.memoryOverhead=1g \
--conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
--conf spark.driver.extraJavaOptions="-XX:+UseConcMarkSweepGC" \
--conf spark.executor.extraJavaOptions="-XX:+UseConcMarkSweepGC" \
--class ${{app_mainclass}} \
$lib_dir/$JARNAME $VARS
